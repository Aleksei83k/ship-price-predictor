# train_model.py
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import joblib
import os

# –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
DATA_PATH = "data/ships.csv"
MODEL_PATH = "data/ship_price_model.pkl"
FEATURES_PATH = "data/ship_price_model_features.pkl"


def detect_separator(file_path, sample_lines=5):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–æ–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ CSV: ',' –∏–ª–∏ ';'"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            sample = ''.join([f.readline() for _ in range(sample_lines)])
        comma_count = sample.count(',')
        semicolon_count = sample.count(';')
        return ';' if semicolon_count > comma_count else ','
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º ',' –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
        return ','


def clean_numeric_column(series):
    """
    –û—á–∏—â–∞–µ—Ç —á–∏—Å–ª–æ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü: —É–¥–∞–ª—è–µ—Ç –ø—Ä–æ–±–µ–ª—ã, –∑–∞–º–µ–Ω—è–µ—Ç –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ),
    –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ float.
    """
    if series.dtype == 'object':
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–Ω—É—Ç—Ä–∏ —á–∏—Å–µ–ª: "10 500 000" ‚Üí "10500000"
        series = series.str.replace(' ', '', regex=False)
        # –ï—Å–ª–∏ –µ—Å—Ç—å –∑–∞–ø—è—Ç—ã–µ –∫–∞–∫ –¥–µ—Å—è—Ç–∏—á–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ ‚Äî –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ —Ç–æ—á–∫–∏
        series = series.str.replace(',', '.', regex=False)
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø
        series = pd.to_numeric(series, errors='raise')
    return series


def main():
    print("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞:", DATA_PATH)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
    if not os.path.exists(DATA_PATH):
        raise FileNotFoundError(f"‚ùå –§–∞–π–ª {DATA_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∏ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞.")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    sep = detect_separator(DATA_PATH)
    print(f"üîç –û–ø—Ä–µ–¥–µ–ª—ë–Ω —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: '{sep}'")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    try:
        data = pd.read_csv(DATA_PATH, sep=sep, encoding='utf-8')
        print("‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω")
    except Exception as e:
        raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")

    # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤: —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    data.columns = data.columns.str.strip().str.lower()
    print("üìä –°—Ç–æ–ª–±—Ü—ã –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏:", data.columns.tolist())

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
    required_columns = ['type', 'dwt', 'year', 'country', 'date', 'price']
    missing_columns = [col for col in required_columns if col not in data.columns]
    if missing_columns:
        raise ValueError(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {missing_columns}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª {DATA_PATH}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –¥–æ –æ—á–∏—Å—Ç–∫–∏
    print("\nüîç –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –¥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π:")
    print(data.dtypes)

    # –û—á–∏—â–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã: dwt –∏ price
    print("\nüßÆ –û—á–∏—â–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã 'dwt' –∏ 'price' –æ—Ç –ø—Ä–æ–±–µ–ª–æ–≤...")
    try:
        data['dwt'] = clean_numeric_column(data['dwt'])
        data['price'] = clean_numeric_column(data['price'])
        print("‚úÖ –°—Ç–æ–ª–±—Ü—ã 'dwt' –∏ 'price' —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç")
    except Exception as e:
        raise ValueError(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤: {e}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —á–∏—Å–µ–ª –≤ —Ñ–∞–π–ª–µ.")

    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    print(f"\nüßπ –ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {len(data)}")
    data = data.dropna()
    print(f"üßπ –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è NaN: {len(data)} —Å—Ç—Ä–æ–∫")

    if len(data) == 0:
        raise ValueError("‚ùå –í—Å–µ —Å—Ç—Ä–æ–∫–∏ —Å–æ–¥–µ—Ä–∂–∞–ª–∏ NaN ‚Äî –¥–∞–Ω–Ω—ã–µ –ø—É—Å—Ç—ã!")

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—É ‚Äî —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
    print("üìÖ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç–æ–ª–±–µ—Ü 'date'...")
    try:
        # –ü—Ä–æ–±—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        data['date'] = pd.to_datetime(data['date'], errors='raise').astype('int64') // 10**9
        print("‚úÖ –î–∞—Ç–∞ —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)")
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏: {e}")
        print("üí° –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã...")

        # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã
        formats_to_try = [
            '%Y-%m-%d',
            '%d.%m.%Y',
            '%m/%d/%Y',
            '%Y/%m/%d',
            '%d-%m-%Y',
            '%Y.%m.%d'
        ]

        success = False
        for fmt in formats_to_try:
            try:
                data['date'] = pd.to_datetime(data['date'], format=fmt).astype('int64') // 10**9
                print(f"‚úÖ –î–∞—Ç–∞ —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ —Å —Ñ–æ—Ä–º–∞—Ç–æ–º: {fmt}")
                success = True
                break
            except:
                continue

        if not success:
            raise ValueError(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å—Ç–æ–ª–±–µ—Ü 'date'. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç –≤ —Ñ–∞–π–ª–µ. –ü—Ä–∏–º–µ—Ä: 2025-07-01")

    # One-hot encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("üî§ –ö–æ–¥–∏—Ä—É–µ–º —Å—Ç–æ–ª–±—Ü—ã 'type' –∏ 'country'...")
    try:
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ type –∏ country ‚Äî —Å—Ç—Ä–æ–∫–∏, –∞ –Ω–µ —á–∏—Å–ª–∞
        data['type'] = data['type'].astype(str)
        data['country'] = data['country'].astype(str)
        data = pd.get_dummies(data, columns=['type', 'country'], drop_first=True)
    except Exception as e:
        raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ü–µ–ª–µ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü 'price' —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if 'price' not in data.columns:
        raise ValueError("‚ùå –°—Ç–æ–ª–±–µ—Ü 'price' –∏—Å—á–µ–∑ –ø–æ—Å–ª–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")

    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    X = data.drop('price', axis=1)
    y = data['price']

    print(f"\nüìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {X.shape[0]} —Å—Ç—Ä–æ–∫, {X.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    if X.shape[0] == 0 or X.shape[1] == 0:
        raise ValueError("‚ùå –î–∞–Ω–Ω—ã–µ –ø—É—Å—Ç—ã –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª.")

    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
    print("üß© –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # –°–æ–∑–¥–∞—ë–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    print("ü§ñ –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å Random Forest...")
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    try:
        model.fit(X_train, y_train)
    except Exception as e:
        raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")

    # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å
    print("üìà –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏...")
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print("\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (MAE): ${mae:,.2f}")
    print(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏ (R¬≤): {r2:.3f}")

    if r2 < 0:
        print("‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: R¬≤ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π ‚Äî –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö—É–∂–µ, —á–µ–º –ø—Ä–æ—Å—Ç–æ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ!")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –≤ {MODEL_PATH}...")
    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)  # —Å–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç

    try:
        joblib.dump(model, MODEL_PATH)
        joblib.dump(X.columns.tolist(), FEATURES_PATH)
        print("üéâ –ú–æ–¥–µ–ª—å –∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")
    except Exception as e:
        raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –≤—ã–≤–æ–¥–∏–º 5 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("\nüîù –¢–æ–ø-5 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    feature_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)
    for i, (feat, imp) in enumerate(feature_importances.head().items(), 1):
        print(f"{i}. {feat}: {imp:.4f}")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        print("üí° –°–æ–≤–µ—Ç: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö, –Ω–∞–ª–∏—á–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤, —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –≤ CSV –∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É.")
        exit(1)